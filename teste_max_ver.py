# -*- coding: utf-8 -*-
"""Welcome To Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

from datetime import datetime
from time import time
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import pymc3 as pm
import warnings
import arviz as az
warnings.filterwarnings('ignore')

def linear_constraint(xmin, xmax, form: str = None):
    '''
    Returns a linear ramp function, for deriving a value on [0, 1] from
    an input value `x`:

        if x >= xmax:
            return 1
        if x <= xmin:
            return 0
        return (x - xmin) / (xmax - xmin)

    Parameters
    ----------
    xmin : int or float
        Lower bound of the linear ramp function
    xmax : int or float
        Upper bound of the linear ramp function
    form : str
        Type of ramp function: "reversed" decreases as x increases;
        "binary" returns xmax when x == 1; default (None) is increasing
        as x increases.

    Returns
    -------
    function
    '''
    assert form is None or form in ('reversed', 'binary'),\
        'Argument "form" must be None or one of: "reversed", "binary"'

    if form == 'reversed':
        return lambda x: pm.math.switch(x >= xmax, 0,
            pm.math.switch(x < xmin, 1, 1 - (x - xmin) / (xmax - xmin)))
    if form == 'binary':
        return lambda x: pm.math.switch(x == 1, xmax, xmin)
    return lambda x: pm.math.switch(x >= xmax, 1,
        pm.math.switch(x < xmin, 0, (x - xmin) / (xmax - xmin)))


def gpp_calc(params, fpar, tmin, vpd, par):
    'Daily GPP as static method, avoids overhead of class instantiation'
    # "params" argument should be a Sequence of atomic parameter values
    #   in the order prescribed by "required_parameters"
    tmin_scalar = linear_constraint(params[1], params[2])(tmin)
    vpd_scalar = linear_constraint(
        params[3], params[4], form = 'reversed')(vpd)
    lue = params[0] * tmin_scalar * vpd_scalar
    return 1e3 * lue * fpar * par

def linear_constraint_normal(
        xmin, xmax, form: str = None):
    '''
    Returns a linear ramp function, for deriving a value on [0, 1] from
    an input value x:

        if x >= xmax:
            return 1
        if x <= xmin:
            return 0
        return (x - xmin) / (xmax - xmin)

    Parameters
    ----------
    xmin : int or float
        Lower bound of the linear ramp function
    xmax : int or float
        Upper bound of the linear ramp function
    form : str
        Type of ramp function: "reversed" decreases as x increases;
        "binary" returns xmax when x == 1; default (None) is increasing
        as x increases.

    Returns
    -------
    function
    '''
    assert form is None or form in ('reversed', 'binary'),\
        'Argument "form" must be None or one of: "reversed", "binary"'
    assert form == 'binary' or np.any(xmax >= xmin),\
        'xmax must be greater than/ equal to xmin'
    if form == 'reversed':
        return lambda x: np.where(x >= xmax, 0,
            np.where(x < xmin, 1, 1 - np.divide(
                np.subtract(x, xmin), xmax - xmin)))
    if form == 'binary':
        return lambda x: np.where(x == 1, xmax, xmin)
    return lambda x: np.where(x >= xmax, 1,
        np.where(x < xmin, 0,
            np.divide(np.subtract(x, xmin), xmax - xmin)))

def gpp_calc_normal(params, fpar, tmin, vpd, par):
    'Daily GPP as static method, avoids overhead of class instantiation'
    # "params" argument should be a Sequence of atomic parameter values
    #   in the order prescribed by "required_parameters"
    tmin_scalar = linear_constraint_normal(params[1], params[2])(tmin)
    vpd_scalar = linear_constraint_normal(
        params[3], params[4], form = 'reversed')(vpd)
    lue = params[0] * tmin_scalar * vpd_scalar
    return 1e3 * lue * fpar * par

parametros = [0.001405, -8.0, 9.09, 1000.0, 4000.0, 26.9, 2.0, 2.0, 1.1, 0.162, 0.00604, 0.00519, 0.00397]
drivers_santarem = np.load('drivers_santarem.npy')
gpp = gpp_calc_normal(parametros,drivers_santarem[0],drivers_santarem[1],drivers_santarem[2],drivers_santarem[3])
index_santarem = pd.date_range(start='2002-01-01', end='2006-12-31', freq='D')
index_santarem = index_santarem.union(pd.date_range(start='2008-01-01', end='2011-12-31', freq='D'))

gpp_santarem = pd.DataFrame(gpp, index=index_santarem)

gpp_santarem = gpp_santarem.rename_axis('index')
gpp_santarem = gpp_santarem[0].rename('GPP')

santarem = pd.read_csv('observacoes_santarem_diario.csv', index_col=0, parse_dates=True,date_format='%Y-%m-%d')

gpp_santarem = gpp_santarem['2002':'2006']
santarem = santarem['2002':'2006']

# Dados observados (exemplo fictício)
observed_data = santarem.values

# Definindo o modelo no PyMC
with pm.Model() as model:
    # Priors para os parâmetros
    tminmin = pm.Uniform('tminmin', lower=-30, upper=8)
    tminmax = pm.Uniform('tminmax', lower=9, upper=50)
    vpdmin = pm.Uniform('vpdmin', lower=50, upper=1000)
    vpdmax = pm.Uniform('vpdmax', lower=1000, upper=7000)
    epsilonj = pm.Uniform('epsilonj', lower=1e-6, upper=1)

    params = [epsilonj, tminmin, tminmax, vpdmin, vpdmax]

    # Previsões
    predictions = gpp_calc(params, drivers_santarem[0][:len(gpp_santarem.index)], drivers_santarem[1][:len(gpp_santarem.index)], drivers_santarem[2][:len(gpp_santarem.index)], drivers_santarem[3][:len(gpp_santarem.index)])

    # Calculando o RMSE
    rmse = pm.math.sqrt(pm.math.sum((predictions - observed_data) ** 2) / predictions.shape[0])

    # Verossimilhança (assumindo uma distribuição normal para o erro)
    likelihood = pm.Normal('likelihood', mu=predictions, sigma=rmse, observed=observed_data)

    # Amostragem utilizando NUTS (No-U-Turn Sampler)
    trace = pm.sample(500, tune=100, return_inferencedata=True)

    # Encontrar o ponto de máxima verossimilhança (MAP - Maximum A Posteriori)
    map_estimate = pm.find_MAP()

# Análise dos resultados
print("Estimativa MAP para tminmin:", map_estimate['tminmin'])
print("Estimativa MAP para tminmax:", map_estimate['tminmax'])
print("Estimativa MAP para vpdmin:", map_estimate['vpdmin'])
print("Estimativa MAP para vpdmax:", map_estimate['vpdmax'])
print("Estimativa MAP para epsilonj:", map_estimate['epsilonj'])

trace.to_netcdf('trace.nc')

before = [0.001405, -8.0, 9.09, 1000.0, 4000.0, 26.9, 2.0, 2.0, 1.1, 0.162, 0.00604, 0.00519, 0.00397]
gpp = gpp_calc_normal(before,drivers_santarem[0][:len(gpp_santarem.index)], drivers_santarem[1][:len(gpp_santarem.index)], drivers_santarem[2][:len(gpp_santarem.index)], drivers_santarem[3][:len(gpp_santarem.index)])
mean_squared_error(observed_data, gpp,squared=False)

from sklearn.metrics import mean_squared_error

new_par = [map_estimate['epsilonj'], map_estimate['tminmin'], map_estimate['tminmax'], map_estimate['vpdmin'], map_estimate['vpdmax']]
new_gpp = gpp_calc_normal(new_par,drivers_santarem[0][:len(gpp_santarem.index)], drivers_santarem[1][:len(gpp_santarem.index)], drivers_santarem[2][:len(gpp_santarem.index)], drivers_santarem[3][:len(gpp_santarem.index)])
mean_squared_error(observed_data, new_gpp,squared=False)

az.plot_trace(trace)